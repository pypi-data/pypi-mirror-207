#!/usr/bin/env python

from __future__ import division, print_function

# Has to be called before importing numpy
from nlsam.multiprocess import multiprocessing_hanging_workaround
multiprocessing_hanging_workaround()

import os
import argparse
import logging
from multiprocessing import cpu_count, freeze_support
from ast import literal_eval

import nibabel as nib
import numpy as np

from nlsam.denoiser import nlsam_denoise
from nlsam.smoothing import local_standard_deviation, sh_smooth, local_piesno
from nlsam.stabilizer import corrected_sigma, stabilization

from dipy.io.gradients import read_bvals_bvecs
from dipy.core.gradients import gradient_table
from dipy.denoise.noise_estimate import piesno


DESCRIPTION = """
Main script for the NLSAM denoising [1], including the stabilizer framework from [2].
"""

EPILOG = """
References :

[1] St-Jean, S., Coupe, P., & Descoteaux, M. (2016).
Non Local Spatial and Angular Matching : Enabling higher spatial resolution diffusion MRI datasets through adaptive denoising.
Medical Image Analysis, 32(2016), 115-130.

[2] Koay CG, Ozarslan E and Basser PJ.
A signal transformational framework for breaking the noise floor and its applications in MRI.
Journal of Magnetic Resonance 2009; 197: 108-119.
"""


def buildArgsParser():

    p = argparse.ArgumentParser(description=DESCRIPTION,
                                epilog=EPILOG,
                                formatter_class=argparse.RawTextHelpFormatter)

    p.add_argument('input', metavar='input',
                   help='Path of the image file to denoise.')

    p.add_argument('output', metavar='output',
                   help='Path for the saved denoised file.')

    p.add_argument('N', metavar='N', type=int,
                   help='Number of receiver coils of the scanner. \n'
                   'Use N=1 in the case of a SENSE (GE, Philips) reconstruction and '
                   'N >= 1 for GRAPPA reconstruction (Siemens).')

    p.add_argument('bvals', metavar='bvals',
                   help='Path of the bvals file, in FSL format.')

    p.add_argument('bvecs', metavar='bvecs',
                   help='Path of the bvecs file, in FSL format.')

    p.add_argument('angular_block_size', metavar='n_angular_neighbors',
                   type=int, help='Number of angular neighbors used for denoising.')

    p.add_argument('--b0_threshold', metavar='int', default=10, type=int,
                   help='Lowest b-value to be considered as a b0. Default 10.')

    p.add_argument('--split_b0s', action='store_true',
                   help='If set and multiple b0s are present, they are split amongst the '
                   'training data.')

    p.add_argument('--block_size', dest='spatial_block_size',
                   metavar='tuple', type=literal_eval, default=(3, 3, 3),
                   help='Size of the 3D spatial patch to be denoised. Default : 3, 3, 3')

    p.add_argument('--fix_implausible', action='store_true', dest='implausible_signal_fix',
                   help='If set, remove physically implausible signals from the input data by setting '
                   'the b0 signal as the highest value along volumes.\nUseful if your data '
                   'is highly noisy and the S0 signal is low.')

    p.add_argument('--is_symmetric', action='store_true',
                   help='If supplied, assumes the set of bvals/bvecs to be already symmetrized,\n'
                   'i.e. All points (x,y,z) on the sphere and (-x,-y,-z) were acquired, such as in full grid DSI.')

    p.add_argument('--iterations', metavar='int', default=10, type=int,
                   help='Maximum number of iterations for the l1 reweighting. Default 10.')

    p.add_argument('--sh_order', metavar='int', default=8, type=int, choices=[0, 2, 4, 6, 8],
                   help='Spherical harmonics order used for sh_smooth.\n'
                   'Use 0 to disable the spherical harmonics fitting. Default 8')

    g = p.add_mutually_exclusive_group()

    g.add_argument('--noise_est', dest='noise_method',
                   metavar='string', default='piesno',
                   choices=['local_std', 'piesno'],
                   help='Noise estimation method used for estimating sigma.\n'
                   'local_std : Compute local noise standard deviation '
                   'with correction factor. No a priori needed.\n'
                   'piesno (default): Use PIESNO estimation, assumes the presence of '
                   'background in the data.')

    g.add_argument('--load_sigma', metavar='file',
                   help='Load this file as the standard deviation volume.\n'
                   'Will be squared internally to turn into variance.')

    g.add_argument('--noise_maps', metavar='file',
                   help='Path of the noise map(s) volume for local piesno.\n'
                   'Either supply a 3D noise map or a stack of 3D maps as a 4D volume.\n'
                   'This is intended for noise maps collected by the scanner (so that there is no signal in those measurements)\n'
                   'which are properly scaled with the rest of the data you collected.\n'
                   'If in doubt, it is safer to use another estimation method with --noise_est')

    p.add_argument('--noise_mask', dest='save_piesno_mask', metavar='file',
                   help='If supplied, output filename for saving the mask of noisy voxels '
                   'found by PIESNO.')

    p.add_argument('--save_stab', metavar='file',
                   help='Path to save the intermediate noisy bias corrected volume. '
                   'Useful for debugging purposes.')

    p.add_argument('--save_sigma', metavar='file',
                   help='Path to save the intermediate standard deviation volume. '
                   'Useful for debugging purposes.')

    p.add_argument('--no_subsample', action='store_false',
                   help='If set, process all the dwis multiple times, '
                   'but note that this option lengthen the total time.\n'
                   'The default is to find the smallest subset so that each dwi is '
                   'processed at least once.')

    p.add_argument('--no_stabilization', action='store_true',
                   help='If set, does not correct the data for the noise non gaussian bias.\n'
                   'Useful if your data is already bias corrected or you would like to do it afterwards.')

    p.add_argument('--no_clip_eta', action='store_false',
                   help='If set, allows eta to take negative values during stabilization.')

    p.add_argument('--no_denoising', action='store_true',
                   help='If set, does not run the nlsam denoising.\n'
                   'Useful if you only want to bias correct your data or get the noise estimation maps only.')

    p.add_argument('--cores', metavar='int', type=int,
                   help='Number of cores to use for multithreading.')

    p.add_argument('--use_threading', action='store_true',
                   help='If set, rely on your blas/lapack/spams multithreading capabilities instead of python multiprocessing.\n'
                   'This mode uses less ram, but is slower than multiprocessing and should only be used for very large datasets\n'
                   'or in cases where the amount of available ram is limited.')

    p.add_argument('--use_f32', action='store_true',
                   help='If supplied, use float32 for inner computations. This option lowers ram usage, but\n'
                   'could lead to numerical precision issues, so use carefully and inspect the final output.')

    p.add_argument('--mp_method', metavar='string',
                   help='Dispatch method for multiprocessing, see\n'
                        'https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods for more information.\n'
                        'Default : None, use the default, platform dependent method to run multiprocessing.\n'
                        'Only available in python 3.4 and later.')

    p.add_argument('-m', '--mask', metavar='file',
                   help='Path to a binary mask. Only the data inside the mask will be reconstructed.')

    p.add_argument('-f', '--force', action='store_true', dest='overwrite',
                   help='If set, the output denoised volume will be overwritten '
                   'if it already exists.')

    p.add_argument('-v', '--verbose', action='store_true',
                   help='If set, print useful information message during processing.')

    p.add_argument('-l', '--log', dest='logfile', metavar='file',
                   help='Save the logging output to this file. Implies verbose output.')

    return p


def main():
    parser = buildArgsParser()
    args = parser.parse_args()

    noise_method = args.noise_method
    sh_order = args.sh_order
    N = args.N

    subsample = args.no_subsample
    is_symmetric = args.is_symmetric
    n_iter = args.iterations
    b0_threshold = args.b0_threshold
    split_b0s = args.split_b0s
    mp_method = args.mp_method
    use_threading = args.use_threading
    block_size = np.array(args.spatial_block_size + (args.angular_block_size,))
    clip_eta = args.no_clip_eta
    logger = logging.getLogger('nlsam')

    if args.logfile is not None:
        handler = logging.FileHandler(args.logfile)
        args.verbose = True
    else:
        handler = logging.StreamHandler(args.logfile)

    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s', "%Y-%m-%d %H:%M:%S")
    handler.setFormatter(formatter)
    logger.addHandler(handler)

    if args.verbose:
        logger.setLevel(logging.INFO)
        logger.info('Verbosity is on')

    if args.no_stabilization:
        logger.info('Stabilization disabled!')

    if args.no_denoising:
        logger.info('Denoising disabled!')

    if args.use_f32:
        logger.info('Computations will be made using float32!')
        dtype = np.float32
    else:
        dtype = np.float64

    if args.use_threading:
        logger.info('Using multithreading instead of multiprocessing, please make sure your blas/lapack/spams '
                    'libraries are built with multithreading support!')

    ##########################################
    #  Load up data and do some sanity checks
    ##########################################

    overwritable_files = [args.output,
                          args.save_sigma,
                          args.save_piesno_mask,
                          args.save_stab]

    for f in overwritable_files:
        if f is not None and os.path.isfile(f):
            if args.overwrite:
                logger.warning('Overwriting {0}'.format(os.path.realpath(f)))
            else:
                parser.error('{0} already exists! Use -f or --force to overwrite it.'.format(f))

    vol = nib.load(args.input)
    data = np.asarray(vol.get_data(caching='unchanged'), dtype=np.float32)
    affine = vol.affine
    header = vol.header
    header.set_data_dtype(np.float32)
    logger.info("Loading data {}".format(os.path.realpath(args.input)))

    if args.mask is not None:
        mask = np.asarray(nib.load(args.mask).get_data(caching='unchanged'), dtype=np.bool)
        logger.info("Loading mask {}".format(os.path.realpath(args.mask)))
    else:
        mask = np.ones(data.shape[:-1], dtype=np.bool)

    bvals, bvecs = read_bvals_bvecs(args.bvals, args.bvecs)
    gtab = gradient_table(bvals, bvecs, b0_threshold=b0_threshold)

    if args.implausible_signal_fix:
        data[..., gtab.b0s_mask] = np.max(data, axis=-1, keepdims=True)
        logger.info("Fixing b0 implausible signals to max(dwi) voxelwise")

    if args.cores is None or args.cores > cpu_count():
        n_cores = cpu_count()
    else:
        n_cores = args.cores

    if len(block_size) != len(data.shape):
        raise ValueError('Block shape {} and data shape {} are not of the same '
                         'length'.format(block_size, data.shape))

    if data.shape[:-1] != mask.shape:
        raise ValueError('data shape is {}, but mask shape {} is different!'.format(data.shape, mask.shape))

    #########################
    #  Noise estimation part
    #########################

    if args.load_sigma is not None:
        sigma = np.asarray(nib.load(args.load_sigma).get_data(caching='unchanged'), dtype=np.float32)
        logger.info("Loading sigma {}".format(os.path.realpath(args.load_sigma)))

        # If we have a bunch of 4D views, we only want a 3D array
        if sigma.ndim == data.ndim:
            sigma = np.median(sigma, axis=-1)
            logger.warning("{} was {}D, but was downcasted to {}D.".format(os.path.realpath(args.load_sigma), sigma.ndim + 1, sigma.ndim))

        if data.shape[:-1] != sigma.shape:
            raise ValueError('data shape is {}, but sigma shape {} is different!'.format(data.shape, sigma.shape))

    elif args.noise_maps is not None:
        noise_maps = np.asarray(nib.load(args.noise_maps).get_data(caching='unchanged'), dtype=np.float32)
        logger.info("Loading {} as a noise map".format(os.path.realpath(args.noise_maps)))

        # Local piesno works on 4D, so we need to broadcast before
        if noise_maps.ndim == 3:
            noise_maps = noise_maps[..., None]

        sigma, mask_noise = local_piesno(noise_maps, N=N, return_mask=True)

        if args.save_piesno_mask is not None:
            nib.save(nib.Nifti1Image(mask_noise.astype(np.int16), affine), args.save_piesno_mask)
            logger.info("Piesno mask saved as {}".format(os.path.realpath(args.save_piesno_mask)))

    elif noise_method == 'piesno':
        logger.info("Estimating noise with method {}".format(noise_method))
        sigma_1D, mask_noise = piesno(data, N=N, return_mask=True)
        sigma = np.broadcast_to(sigma_1D[None, None, :, None], data.shape)

        if args.save_piesno_mask is not None:
            nib.save(nib.Nifti1Image(mask_noise.astype(np.int16), affine), args.save_piesno_mask)
            logger.info("Piesno mask saved as {}".format(os.path.realpath(args.save_piesno_mask)))

        # If the detected noise standard deviation is low and the noise mask has few voxels,
        # maybe something went wrong. We check here that at least 1% of noisy voxels
        # were found and warn the user otherwise.
        frac_noisy_voxels = np.sum(mask_noise) / np.size(mask_noise) * 100

        if frac_noisy_voxels < 1.:
            logger.warning('PIESNO was used with N={}, but it found only {:.3f}%'
                           ' of voxels as pure noise with a mean standard deviation'
                           ' of {:.5f}. This is suspicious, so please check'
                           ' the resulting sigma volume if something went wrong.'
                           ' In cases where PIESNO is not working, you might want to try'
                           ' --noise_est local_std'.format(N, frac_noisy_voxels, np.mean(sigma_1D)))

    elif noise_method == 'local_std':
        logger.info("Estimating noise with method {}".format(noise_method))
        sigma = local_standard_deviation(data, n_cores=n_cores, mp_method=mp_method)

        # Compute the corrected value for each 3D volume
        if N > 0:
            sigma = np.broadcast_to(sigma[..., None], data.shape)
            mask_4D = np.broadcast_to(mask[..., None], data.shape)
            sigma = corrected_sigma(data, sigma, mask_4D, N, n_cores=n_cores, mp_method=mp_method)

    if args.save_sigma is not None:
        nib.save(nib.Nifti1Image(sigma, affine), args.save_sigma)
        logger.info("Sigma map saved as {}".format(os.path.realpath(args.save_sigma)))

    ##################
    #  Stabilizer part
    ##################

    if args.no_stabilization:
        data_stabilized = data
    else:
        logger.info("Now performing stabilization")

        if sh_order <= 0:
            m_hat = data
        else:
            logger.info("Estimating m_hat with sh order {}".format(sh_order))

            # Raise warning for sh order if there is not enough DWIs
            required_dwis = int((sh_order + 1) * (sh_order + 2) / 2)
            number_of_dwis = data.shape[-1] - np.sum(gtab.b0s_mask)
            if number_of_dwis < required_dwis:
                logger.warning('We recommend having at least {} unique DWIs volumes, '
                               'but you currently have {} volumes. Try lowering the '
                               'parameter --sh_order in case of non '
                               'convergence.'.format(required_dwis, number_of_dwis))

            m_hat = sh_smooth(data, gtab, sh_order=sh_order).clip(min=0)

        # We may have a 3D sigma map, so broadcast to 4D for indexing
        if sigma.ndim == 3:
            sigma = np.broadcast_to(sigma[..., None], data.shape)

        data_stabilized = stabilization(data, m_hat, mask, sigma, N, n_cores=n_cores, mp_method=mp_method, clip_eta=clip_eta)
        del m_hat

        if args.save_stab is not None:
            nib.save(nib.Nifti1Image(data_stabilized, affine), args.save_stab)
            logger.info("Stabilized data saved as {}".format(os.path.realpath(args.save_stab)))

    ##################
    #  Denoising part
    ##################

    if not args.no_denoising:
        logger.info("Now denoising ".format(os.path.realpath(args.input)))

        # If we have a bunch of 4D views, we only want a 3D array
        if sigma.ndim == data.ndim:
            sigma = np.median(sigma, axis=-1)
        del data

        data_denoised = nlsam_denoise(data_stabilized, sigma, bvals, bvecs, block_size,
                                      mask=mask,
                                      is_symmetric=is_symmetric,
                                      n_cores=n_cores,
                                      split_b0s=split_b0s,
                                      subsample=subsample,
                                      n_iter=n_iter,
                                      b0_threshold=b0_threshold,
                                      dtype=dtype,
                                      use_threading=use_threading,
                                      mp_method=mp_method)

        nib.save(nib.Nifti1Image(data_denoised.astype(np.float32), affine, header), args.output)
        logger.info("Denoised data saved as {}".format(os.path.realpath(args.output)))


if __name__ == "__main__":
    freeze_support()
    main()
