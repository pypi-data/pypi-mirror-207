Metadata-Version: 2.1
Name: spacy-to-hf
Version: 0.0.1
Summary: Spacy to HF converter
Author-email: Ben Epstein <ben.epstein97+spacy-hf@gmail.com>
License: Apache 2.0
Project-URL: Documentation, https://github.com/ben-epstein/spacy-to-hf
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: spacy (<3)
Requires-Dist: pytokenizations
Requires-Dist: transformers
Requires-Dist: flax
Provides-Extra: dev
Requires-Dist: black (>=21.10b0) ; extra == 'dev'
Requires-Dist: coverage (>=6.1.1) ; extra == 'dev'
Requires-Dist: invoke (>=2.0.0) ; extra == 'dev'
Requires-Dist: mypy (>=0.910) ; extra == 'dev'
Requires-Dist: packaging (>=21.0) ; extra == 'dev'
Requires-Dist: pre-commit (>=2.17.0) ; extra == 'dev'
Requires-Dist: pytest (>=6.2.5) ; extra == 'dev'
Requires-Dist: pytest-cov (>=3.0.0) ; extra == 'dev'
Requires-Dist: ruff (>=0.0.98) ; extra == 'dev'
Requires-Dist: build (>=0.7.0) ; extra == 'dev'

# spacy-to-hf
A simple converter from Spacy Entities to Huggingface BILOU formatted data

I've always struggled to convert my spacy formatted spans into data that can be trained
on using huggingface transformers. But Spacy's Entity format is the most intuitive
format for tagging entities for NER.

This repo is a simple converter that leverages `spacy.gold.biluo_tags_from_offsets`
and the SpaCy `tokenizations` repo that creates a 1-line function to convert spacy
formatted spans to `tokens` and `ner_tags` that can be fed into any
Token Classification Transformer

## Installation
```shell
pip install spacy-to-hf
python -m spacy download en_core_web_sm
````

## Usage
```python
from spacy_to_hf import spacy_to_hf
from datasets import Dataset

span_data = [
    {
        "text": "I have a BSc (Bachelors of Computer Sciences) from NYU",
        "spans": [
            {"start": 9, "end": 12, "label": "degree"},
            {"start": 14, "end": 44, "label": "degree"},
            {"start": 51, "end": 54, "label": "university"}
        ]
    }
]
hf_data = spacy_to_hf(span_data, "bert-base-cased")
print(list(zip(hf_data["tokens"][0], hf_data["ner_tags"][0])))
ds = Dataset.from_dict(hf_data)
```

From here, you can label-index your ner_tags and prepare for fine-tuning

## Project Setup
Project setup is credited to @anthonycorletti and his awesome repo
https://github.com/anthonycorletti/python-project-template
