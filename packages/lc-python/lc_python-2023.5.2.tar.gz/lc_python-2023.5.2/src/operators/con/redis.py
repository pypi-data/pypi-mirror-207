import time

import redis as pyredis
import ujson as json
from devapp.app import app
from devapp.tools import FLG, define_flags, get_deep
from operators.con.connections import con_params
from operators.dec_enc import decode_msg, encode_msg, from_flat_json, msg_key
from operators.kv_tools import kv

#         v = data
#         for p in pth:
#             v = v.get(p)
#             if v == None:
#                 app.warn('Key not found', pth=pth)
#                 return
#         return v


# def get_con_params(cls):
#     d = con_params(cls, use_dflt=True)
#     breakpoint()  # FIXME BREAKPOINT
#     p = {
#         'db': d.get('db', 0),
#         'host': d['hostname'],
#         'port': d.get('port', 6379),
#     }
#     cls.host_short = h = p['host']
#     if h in {'localhost', '127.0.0.1'}:
#         cls.host_short = 'L'

#     if d.get('password'):
#         p['password'] = d['password']
#     return p


def set_host_params(cls, p):
    cls.port = p['port']
    _ = {'localhost', '127.0.0.1'}
    cls.host_short = 'L' if p['host'] in _ else p['host']


class redis:
    name = 'redis'
    multi_url = True

    class con_defaults:
        # fmt:off
        _strip_non_default_keys  = True
        _cast                    = True
        _use                     = True
        charset                  = None
        client_name              = None
        db                       = 0
        decode_responses         = False
        encoding                 = 'utf-8'
        encoding_errors          = 'strict'
        errors                   = None
        health_check_interval    = 5
        host                     = '127.0.0.1'
        max_connections          = None
        password                 = None
        port                     = 6379
        retry_on_timeout         = True
        single_connection_client = False
        socket_connect_timeout   = None
        socket_keepalive         = None
        socket_keepalive_options = None
        socket_timeout           = 2
        ssl                      = False
        ssl_ca_certs             = None
        ssl_cert_reqs            = 'required'
        ssl_certfile             = None
        ssl_check_hostname       = False
        ssl_keyfile              = None
        unix_socket_path         = None
        username                 = None
        # fmt:on

    _con_ = None
    _pool_ = None
    host_short = None

    @classmethod
    def _con(cls):
        # we return a standing connection, not pool managed, since this is 2.5x slower, for fast get/set
        if cls._con_ is None:
            p = cls._con_params = con_params(cls, defaults=cls.con_defaults)
            set_host_params(cls, p[0])
            if len(p) == 1:
                cls._con_ = pyredis.Redis(**p[0])
            else:
                C = pyredis.cluster
                h, port, password = p[0]['host'], p[0]['port'], p[0].get('password')
                N = C.ClusterNode
                nodes = [N(i.get('host', h), port=i.get('port', port)) for i in p]
                cls._con_ = C.RedisCluster(startup_nodes=nodes, password=password)
        return cls._con_

    @classmethod
    def _pool(cls):
        """we return a pool mangaged conn"""
        # return pyredis.Redis(host, port)
        return cls._con()  # has a con pool internally

        # if cls._pool_ is None:
        #     p = con_params(cls, dflt_keys=True)
        #     breakpoint()  # FIXME BREAKPOINT
        #     p = connection_pool = pyredis.ConnectionPool(**p)
        #     cls._pool_ = pyredis.Redis(connection_pool=p)
        # breakpoint()  # FIXME BREAKPOINT
        # return cls._pool_

    @classmethod
    def monitor(cls, observer):
        """Observing whats going on on redis

        Note: In cluster mode you'll see only the transactions on your configured
        startup nodes.
        """
        con = cls._con()
        with con.monitor() as m:
            for command in m.listen():
                observer.on_next(command)

    @classmethod
    def src(cls, observer, name='ax_stream'):
        """
        xread from a redis stream generated by us, i.e. messages with headers
        """
        con = cls._pool()
        m = {name: '$'}   # forget history for stream(s) called `name`, get from NOW
        r = con.xread(m, None, 100)
        while True:
            for n in r:
                name, d = n[0], n[1]
                ns = [name, cls.host_short, cls.port]
                for rec in d:
                    id = rec[0]
                    d = rec[1][msg_key]
                    msg = decode_msg(d)
                    msg['_ids']['strm'] = ns
                    observer.on_next(msg)
                    time.sleep(0)
                m[name] = id   # from now on read from last one processed
            r = con.xread(m, None, 100)

    @classmethod
    def snk(cls, data, msg, name='ax_stream', enc=None):
        """
        Simple full message forwarder.
        In order to push dedicated payloads, snk to set_events.
        """
        con = cls._con()
        m, is_bin = encode_msg(msg, enc=enc)
        con.xadd(name, {msg_key: m})

    @classmethod
    def get(
        cls,
        data,
        msg,
        key='{d[id]}',
        pth=None,
        pth_sep='.',
        create=True,
        head=False,
        enc='auto',
    ):
        """
        Reads data from redis, then adds it into the data structure.
        lookup may be deep key within data
        {
        """
        keyv = key.format(d=data, m=msg)
        con = cls._con()
        v = con.get(keyv)
        if not v:
            return data if pth is None else v

        v = decode_msg(v)

        if pth is None:
            return v
        return kv.update(
            data, msg, pth=pth, pth_sep=pth_sep, create=create, head=head, **v
        )

    @classmethod
    def get_events(
        cls,
        data,
        msg,
        key='events:{d[id]}',
        pth=None,
        pth_sep='.',
        create=True,
        head=False,
        count=None,
    ):
        """
        xrevrange, i.e. querying a stream as a time series db
        pth: None -> returns the events
             True -> inplace add under top level key 'events'
             'foo.bar' -> inplace add under ['foo']['bar']]['events']
        """
        keyv = key.format(d=data, m=msg)
        con = cls._con()
        evts = con.xrevrange(keyv, count=count)
        r = []
        for e in evts:
            ts, m = e
            # fixme:
            m = from_flat_json(m)
            r.append([int(ts.decode('utf-8').split('-', 1)[0]), m])
        if pth is None:
            return r
        if pth == True:
            # add under top level key "events"
            path = ''
        kv.update(data, msg, pth, create=create, head=head, events=r)

    @classmethod
    def set(
        cls,
        data,
        msg,
        key='{d[id]}',
        pth=None,
        pth_sep='.',
        create=False,
        head=False,
        ex=3600,
        px=None,
        nx=False,
        xx=False,
        keepttl=False,
        enc='json',
        _no_write=False,
        **kw
    ):
        """
        sig compat with ax:set regarding common keys
        """
        if px:
            ex = None
        # key='{d[id]}',
        keyv = key.format(d=data, m=msg)
        kw = kw if _no_write is False else _no_write
        if kw:
            kv.update(data, msg, pth=pth, pth_sep=pth_sep, create=create, head=head, **kw)

        v = get_deep(key=pth, data=data, sep=pth_sep, create=create)

        con = cls._con()

        v = encode_msg(v, enc=enc)[0]

        if _no_write is not False:
            return con, keyv, v

        con.set(keyv, v, ex=ex, px=px, nx=nx, xx=xx, keepttl=keepttl)

    @classmethod
    def set_events(
        cls,
        data,
        msg,
        key='events:{d[id]}',
        pth=None,
        pth_sep='.',
        create=False,
        head=False,
        maxlen=10,
        ignore=None,
        enc='json_flat',
        _pipeline=False,
        **kw
    ):
        """Redis streams write"""
        if isinstance(data, list) and msg.get('is_aggr') and '{d' in key:
            l = dict(locals())
            l.pop('cls')
            # we get a batch which we have to write one by one, since key is per data
            # -> go pipeline
            pipe = cls._con().pipeline()
            l['_pipeline'] = pipe
            for d in data:
                l['data'], l['msg'] = d['payload'], d
                cls.set_events(**l)
            pipe.execute()
            return

        if ignore:
            # just one top level key currently:
            ign = {}
            for i in ignore:
                ign[i] = data.pop(i, None)

        con, keyv, v = cls.set(
            data,
            msg,
            key,
            pth,
            pth_sep,
            create,
            head,
            enc=enc,
            _no_write=kw,
        )
        # res is only the timestamp:
        if _pipeline:
            con = _pipeline
        # API is strange, reuireds dict:
        if not isinstance(v, dict):
            v = {msg_key: v}
        res = con.xadd(name=keyv, fields=v, maxlen=maxlen, approximate=True)
        if ignore:
            data.update(ign)
