# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['featurebyte',
 'featurebyte.api',
 'featurebyte.api.templates',
 'featurebyte.api.templates.online_serving',
 'featurebyte.common',
 'featurebyte.common.documentation',
 'featurebyte.common.documentation.markdown_extension',
 'featurebyte.core',
 'featurebyte.core.accessor',
 'featurebyte.datasets',
 'featurebyte.docker',
 'featurebyte.feature_manager',
 'featurebyte.migration',
 'featurebyte.migration.service',
 'featurebyte.models',
 'featurebyte.persistent',
 'featurebyte.query_graph',
 'featurebyte.query_graph.graph_node',
 'featurebyte.query_graph.model',
 'featurebyte.query_graph.node',
 'featurebyte.query_graph.node.metadata',
 'featurebyte.query_graph.sql',
 'featurebyte.query_graph.sql.aggregator',
 'featurebyte.query_graph.sql.ast',
 'featurebyte.query_graph.sql.interpreter',
 'featurebyte.query_graph.transform',
 'featurebyte.routes',
 'featurebyte.routes.batch_feature_table',
 'featurebyte.routes.batch_request_table',
 'featurebyte.routes.catalog',
 'featurebyte.routes.common',
 'featurebyte.routes.context',
 'featurebyte.routes.credential',
 'featurebyte.routes.deployment',
 'featurebyte.routes.dimension_table',
 'featurebyte.routes.entity',
 'featurebyte.routes.event_table',
 'featurebyte.routes.feature',
 'featurebyte.routes.feature_job_setting_analysis',
 'featurebyte.routes.feature_list',
 'featurebyte.routes.feature_list_namespace',
 'featurebyte.routes.feature_namespace',
 'featurebyte.routes.feature_store',
 'featurebyte.routes.historical_feature_table',
 'featurebyte.routes.item_table',
 'featurebyte.routes.observation_table',
 'featurebyte.routes.periodic_tasks',
 'featurebyte.routes.relationship_info',
 'featurebyte.routes.scd_table',
 'featurebyte.routes.semantic',
 'featurebyte.routes.table',
 'featurebyte.routes.task',
 'featurebyte.routes.temp_data',
 'featurebyte.schema',
 'featurebyte.schema.common',
 'featurebyte.schema.worker',
 'featurebyte.schema.worker.task',
 'featurebyte.service',
 'featurebyte.service.validator',
 'featurebyte.session',
 'featurebyte.sql',
 'featurebyte.sql.spark',
 'featurebyte.storage',
 'featurebyte.tile',
 'featurebyte.utils',
 'featurebyte.utils.snowflake',
 'featurebyte.worker',
 'featurebyte.worker.task']

package_data = \
{'': ['*'],
 'featurebyte.query_graph.node.metadata': ['templates/*'],
 'featurebyte.sql': ['databricks/*', 'snowflake/*']}

install_requires = \
['PyYAML>=6.0,<7.0',
 'aiofiles>=22.1.0,<23.0.0',
 'alive-progress>=3.1.1,<4.0.0',
 'asyncache>=0.3.1,<0.4.0',
 'black>=23.3.0,<24.0.0',
 'cryptography>=40.0.2,<41.0.0',
 'humanize>=4.4.0,<5.0.0',
 'jinja2>=3.1.2,<4.0.0',
 'lazy-object-proxy>=1.7.1,<2.0.0',
 'orjson>=3.8.3,<4.0.0',
 'pandas>=1.5.3,<2.0.0',
 'pyarrow>=10,<11',
 'pydantic>=1.9.6,<2.0.0',
 'pymongo>=4.1.1,<5.0.0',
 'python-multipart>=0.0.6,<0.0.7',
 'python-on-whales>=0.60.0,<0.61.0',
 'requests>=2.27.1,<3.0.0',
 'rich>=13.3.4,<14.0.0',
 'sqlglot>=10.1.3,<10.4',
 'typeguard>=2.13.3,<3.0.0',
 'typer>=0.7.0,<0.8.0',
 'websocket-client>=1.5.1,<2.0.0',
 'wheel==0.40.0']

extras_require = \
{':python_version >= "3.8" and python_version < "4.0"': ['importlib_metadata>=4.5.0,<5.0.0'],
 'server': ['aioredis>=2.0.1,<3.0.0',
            'boto3==1.24.59',
            'cachetools>=5.2.0,<6.0.0',
            'celery[redis]>=5.2.6,<6.0.0',
            'celerybeat-mongo>=0.2.0,<0.3.0',
            'databricks-cli>=0.17.3,<0.18.0',
            'databricks-sql-connector>=2.5.0,<3.0.0',
            'fastapi>=0.95.1,<0.96.0',
            'featurebyte-freeware>=0.2.14,<0.3.0',
            'gevent>=22.10.2,<23.0.0',
            'motor>=3.0.0,<4.0.0',
            'pdfkit>=1.0.0,<2.0.0',
            'pyhive>=0.6.5,<0.7.0',
            'redis>=5.0.0b1,<6.0.0',
            'sasl>=0.3.1,<0.4.0',
            'smart-open>=6.3.0,<7.0.0',
            'snowflake-connector-python>=3.0.3,<4.0.0',
            'thrift-sasl>=0.4.3,<0.5.0',
            'uvicorn[standard]>=0.21.1,<0.22.0']}

entry_points = \
{'console_scripts': ['featurebyte = featurebyte.__main__:app']}

setup_kwargs = {
    'name': 'featurebyte',
    'version': '0.2.1',
    'description': 'Python Library for FeatureOps',
    'long_description': '<h1 align="center"> The modern Feature Engineering & Management platform</h1>\n<div align="center">\n\n[![Build status](https://github.com/featurebyte/featurebyte/workflows/build/badge.svg?branch=main&event=push)](https://github.com/featurebyte/featurebyte/actions?query=workflow%3Abuild)\n[![Python Version](https://img.shields.io/pypi/pyversions/featurebyte.svg)](https://pypi.org/project/featurebyte/)\n[![Dependencies Status](https://img.shields.io/badge/dependencies-up%20to%20date-brightgreen.svg)](https://github.com/featurebyte/featurebyte/pulls?utf8=%E2%9C%93&q=is%3Apr%20author%3Aapp%2Fdependabot)\n\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![Security: bandit](https://img.shields.io/badge/security-bandit-green.svg)](https://github.com/PyCQA/bandit)\n[![Pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/featurebyte/featurebyte/blob/main/.pre-commit-config.yaml)\n[![Semantic Versions](https://img.shields.io/badge/%20%20%F0%9F%93%A6%F0%9F%9A%80-semantic--versions-e10079.svg)](https://github.com/featurebyte/featurebyte/releases)\n[![License](https://img.shields.io/github/license/featurebyte/featurebyte)](https://github.com/featurebyte/featurebyte/blob/main/LICENSE)\n![Coverage Report](https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/kchua78/773e2960183c0a6fe24c644d95d71fdb/raw/coverage.json)\n\n</div>\n\nFeatureByte is a **free and source available feature platform** designed to:\n\n* **Create state-of-the-art features, not data pipelines:** Create features for Machine Learning with just a few lines of code. Leave the plumbing and pipelining to FeatureByte. We take care of orchestrating the data ops - whether it’s time-window aggs or backfilling, so you can deliver more value from data.\n* **Improve Accuracy through data:** Use the intuitive feature declaration framework to transform creative ideas into training data in minutes. Ditch the limitations of ad-hoc pipelines for features with much more scale, complexity and freshness.\n* **Streamline machine learning data pipelines:** Get more value from AI. Faster. Deploy and serve features in minutes, instead of weeks or months. Declare features in Python and automatically generate optimized data pipelines — all using tools you love like Jupyter Notebooks.\n\n\n\n\n## Take charge of the entire ML feature lifecycle\n\nFeature Engineering and management doesn’t have to be complicated. Take charge of the entire ML feature lifecycle. With FeatureByte, you can **create, experiment, serve and manage your features in one tool**.\n\n### Create\n- Create and share state-of-the-art ML features effortlessly\n- Search and reuse features to create feature lists tailored to your use case\n\n``` python\n# Get view from catalog\ninvoices = catalog.get_view("INVOICES")\n# Customer average spend over past 5 weeks\nfeatures = invoices.groupby(\n    "CustomerId"\n).aggregate_over(\n    "Amount",\n    method="avg",\n    feature_names=["AvgSpend5w"],\n    fill_value=0,\n    windows=["5w"]\n)\n# Save feature\nfeatures["AvgSpend5w"].save()\n```\n\n### Experiment\n- Immediately access historical features through automated backfilling - let FeatureByte handle the complexity of time-aware SQL\n- Experiment on live data at scale, innovating faster\n- Iterate rapidly with different feature lists to create more accurate models\n\n``` python\n# Get feature list from the catalog\nfeature_list = catalog.get_feature_list(\n    "200 Features on Active Customers"\n)\n# Get an observation set from the catalog\nobservation_set = catalog.get_observation_table(\n    "5M rows of active Customers in 2021-2022"\n)\n# Compute training data and\n# store it in the feature store for reuse and audit\ntraining = \\\n    feature_list.compute_historical_feature_table(\n      observation_set,\n      name="Training set to predict purchases next 2w"\n    )\n```\n\n### Serve\n- Deploy AI data pipelines and serve features in minutes\n- Access features with low latency\n- Reduce costs and security risk by performing computations in your existing data platform\n- Ensure data consistency between model training and inferencing\n\n``` python\n# Get feature list from the catalog\nfeature_list = catalog.get_feature_list(\n    "200 Features on Active Customers"\n)\n# Create deployment\ndeployment = feature_list.deploy(\n    name="Features for customer purchases next 2w",\n)\n# Activate deployment\ndeployment.enable()\n# Get shell script template for online serving\ndeployment.get_online_serving_code(language="sh")\n```\n\n### Manage\n- Organize feature engineering assets with domain-specific catalogs\n- Centralize cleaning operations and feature job configurations\n- Differentiate features that are prototype versus production ready\n- Create new versions of your features to handle changes in data\n- Keep full lineage of your training data and features in production\n- Monitor the health of feature pipelines centrally\n\n``` python\n# Get table from catalog\nitems_table = catalog.get_table("GROCERYITEMS")\n\n# Discount must not be negative\nitems_table.Discount.update_critical_data_info(\n    cleaning_operations=[\n        fb.MissingValueImputation(\n            imputed_value=0\n        ),\n        fb.ValueBeyondEndpointImputation(\n            type="less_than",\n            end_point=0,\n            imputed_value=0\n        ),\n    ]\n)\n```\n\nGet an [overview of the typical workflow](https://docs.featurebyte.com/latest/about/workflow/) in FeatureByte.\n\n## Get started with Quick-Start and Deep-Dive Tutorials\nDiscover FeatureByte via its tutorials. All you need is to install the FeatureByte SDK.\n\nInstall FeatureByte SDK with pip:\n```shell\npip install featurebyte\n```\n**Note**: To avoid potential conflicts with other packages it is strongly recommended to use a [virtual environment](https://docs.python.org/3/tutorial/venv.html) or a [conda environment](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html).\n\nRun the following python code to start the FeatureByte services locally with [Docker](https://docs.docker.com/engine/install/).\n``` python\nimport featurebyte as fb\nfb.playground()\n```\nThis will create a local Spark data warehouse with pre-populated data. Once the environment is ready, you can [download](https://docs.featurebyte.com/latest/get_started/tutorials/overview/#download-tutorials) and run notebooks from the [tutorials](https://docs.featurebyte.com/latest/get_started/tutorials/overview/) section.\n\n## Leverage your data warehouse\n\nFeatureByte is developed to integrate seamlessly with your **Snowflake, Databricks, or Spark** data warehouses, enhancing security and efficiency by bypassing large-scale outbound data transfers. This integration allows feature calculations to be performed within the data warehouse, leveraging scalability, stability, and efficiency.\n\n<div align="center">\n  <img src="./assets/images/Data%20Warehouse.png" width="600" alt="Warehouse Diagram">\n</div>\n\nFeatureByte utilizes your data warehouse as a:\n\n* data source.\n* compute engine to leverage its scalability, stability, and efficiency.\n* storage of partial aggregates (tiles) and precomputed feature values to support feature serving.\n\nMore data warehouses will be supported soon!\n\n## Architecture\n\n![FeatureByte Architecture](./assets/images/system_architecture.png)\nThe FeatureByte platform comprises the following components:\n- **FeatureByte SDK** (Python Package): Connects to the API service to provide feature authoring and management functionality through python classes and functions.\n- **FeatureByte Service** (Docker Containers):\n  - **API Service**: REST-API service that validates and executes requests, queries data warehouses, and stores data.\n  - **Worker**: Executes asynchronous or scheduled tasks.\n  - **MongoDB**: Store metadata for created assets.\n  - **Redis**: Broker and queue for workers, messenger service for publishing progress updates.\n- **Query Graph Transpiler** (Python Package): Construct data transformation steps as a query graph, which can be transpiled to platform-specific SQL.\n- **Source Tables** (Data Warehouse): Tables used as data sources for feature engineering.\n- **Feature Store** (Data Warehouse): Database that store data used to support feature serving.\n\n## FeatureByte Service Deployment Options\nThe **FeatureByte Service** can be installed in three different modes:\n\n* **Local installation:** The easiest way to get started with the FeatureByte SDK. It is a single-user installation that can be used to prototype features locally with your data warehouse.\n\n\n* **Hosted on a single server:** A light-weight option to support collaboration and job scheduling with limited scalability and availability. Multiple users can connect to the service using the FeatureByte SDK, and deploy features for production.\n\n\n* **High availability installation (coming soon):** The recommended way to run the service in production. Scale to a large number of users and deployed features, and provide highly available services.\n\nThe FeatureByte Service runs on **Docker** for the first two installation modes, and is deployed on a **Kubernetes Cluster** for the high availability installation mode.\n\nRefer to the [installation](https://docs.featurebyte.com/latest/get_started/installation/) section of the documentation for more details.\n\n## FeatureByte SDK\n\nThe FeatureByte Python SDK offers a comprehensive set of objects for feature engineering, simplifying the management and manipulation of tables, entities, views, features, feature lists and other necessary objects for feature serving.\n\n* [**Catalog**](https://docs.featurebyte.com/latest/reference/core/catalog/) objects help you organize your feature engineering assets per domain and maintain clarity and easy access to these assets.\n* [**Entity**](https://docs.featurebyte.com/latest/reference/core/entity/) objects contain metadata on entity types represented or referenced by tables within your data warehouse.\n* [**Table**](https://docs.featurebyte.com/latest/reference/core/table/) objects centralize key metadata about the table type, important columns, default cleaning operations and default feature job configurations.\n* [**View**](https://docs.featurebyte.com/latest/reference/core/view/) objects work like SQL views and are local virtual tables that can be modified and joined to other views to prepare data before feature definition.\n* [**Feature**](https://docs.featurebyte.com/latest/reference/core/feature/) objects contain the logical plan to compute a feature in the form of a feature definition file.\n* [**FeatureList**](https://docs.featurebyte.com/latest/reference/core/feature_list/) objects are collection of Feature objects tailored to meet the needs of a particular use case.\n\nRefer to the [SDK overview](https://docs.featurebyte.com/latest/about/sdk_overview/) for a complete list of the objects supported by the SDK and the SDK reference for more information about each object.\n\n## Feature Creation\n\nThe SDK offers an intuitive declarative framework to create feature objects with different signal types, including timing, regularity, stability, diversity, and similarity in addition to the traditional recency, frequency and monetary types.\n\n### Examples\nFeatures can be as simple as an entity’s attribute:\n\n``` python\ncustomer_view = catalog.get_view("GROCERYCUSTOMER")\n# Extract operating system from BrowserUserAgent column\ncustomer_view["OperatingSystemIsWindows"] = \\\n    customer_view.BrowserUserAgent.str.contains("Windows")\n# Create a feature indicating whether the customer is using Windows\nuses_windows = customer_view.OperatingSystemIsWindows.as_feature("UsesWindows")\n```\n\nFeatures can be more complex such as aggregations over a window:\n\n``` python\ninvoice_view = catalog.get_view("GROCERYINVOICE")\n# Group invoices by the column GroceryCustomerGuid that references the customer entity\ninvoices_by_customer = invoice_view.groupby("GroceryCustomerGuid")\n# Declare features of total spent by customer over the past 7 days and 28 days\ncustomer_purchases = invoices_by_customer.aggregate_over(\n    "Amount",\n    method=fb.AggFunc.SUM,\n    feature_names=["CustomerTotalSpent_7d", "CustomerTotalSpent_28d"],\n    fill_value=0,\n    windows=[\'7d\', \'28d\']\n)\n```\n\nTo capture more complex signals, features can involve a series of joins and aggregates and be derived from multiple features:\n\n``` python\n# Get items and product view from the catalog\nitems_view = catalog.get_view("INVOICEITEMS")\nproduct_view = catalog.get_view("GROCERYPRODUCT")\n# Join product view to items view\nitems_view = items_view.join(product_view)\n# Get Customer purchases across product group over the past 4 weeks\ncustomer_inventory_28d = items_view.groupby(\n    by_keys = "GroceryCustomerGuid", category=”ProductGroup”\n).aggregate_over(\n   "TotalCost",\n    method=fb.AggFunc.SUM,\n    feature_names=["CustomerInventory_28d"],\n    windows=[\'28d\']\n)\n# Get customer view and join it to items view\ncustomer_view = catalog.get_view("GROCERYCUSTOMER")\nitems_view = items_view.join(customer_view)\n# Get Purchases of Customers living in the same state\n# across product group over the past 4 weeks\nstate_inventory_28d = items_view.groupby(\n    by_keys="State", category="ProductGroup"\n).aggregate_over(\n   "TotalCost",\n    method=fb.AggFunc.SUM,\n    feature_names=["StateInventory_28d"],\n    windows=[\'28d\']\n)\n# Create a feature that measures the similarity of a customer purchases\n# and purchases of customers living in the same state\ncustomer_state_similarity_28d = \\\n    customer_inventory_28d["CustomerInventory_28d"].cd.cosine_similarity(\n        state_inventory_28d["StateInventory_28d"]\n    )\n# save the new feature\ncustomer_state_similarity_28d.name = \\\n    "Customer Similarity with purchases in the same state over 28 days"\ncustomer_state_similarity_28d.save()\n```\n\n### Feature Definition\nOnce a feature is defined, you can obtain its feature definition file that is the source of truth and provides an explicit outline of the intended operations of the feature declaration, including those inherited but not explicitly declared by you.\n\n``` python\ncustomer_state_similarity_28d.definition\n```\n\nRefer to the SDK reference for the [Feature](https://docs.featurebyte.com/latest/reference/core/feature/) object for more information.\n\n## Time Travel\n\nGreat Machine Learning models require great training data. Great training data require great features (columns) and great observation data points (rows). Great observation data points are historical data points that replicate the production environment. If predictions are expected to be any time, observation points-in-time should also be any time during a period covering at least one seasonal cycle.\n\nObservation data points are in FeatureByte in the form of observation sets that combine entity values and any past points-in-time you want to learn from.\n\nYou can choose to get training data as a Pandas DataFrame or as a Table in the feature store that contains metadata on how the table was created for reuse or audit.\n\n``` python\n# Get feature list from the catalog\nfeature_list = catalog.get_feature_list(\n    "200 Features on Active Customers"\n)\n# Create a new feature list that includes a new feature\ncustomer_state_similarity_28d = catalog.get_feature(\n    "Customer Similarity with purchases in the same state over 28 days"\n)\nnew_feature_list = fb.FeatureList(\n    [feature_list, customer_state_similarity_28d],\n    name="Improved feature list with Customer State similarity"\n)\n# Get an observation set from the catalog\nobservation_set = catalog.get_observation_table(\n    "5M of active Customers in 2021-2022"\n)\n# Compute training data and store it in the feature store for reuse and audit\ntraining_table = new_feature_list.compute_historical_feature_table(\n    observation_set,\n    name="Improved Data to predict purchases next 2w with 2021-2022 history"\n)\n# Download training data as a Pandas DataFrame\ntraining_df = training_table.to_pandas()\n```\n\nRefer to the SDK reference for the [FeatureList](https://docs.featurebyte.com/latest/reference/core/feature_list/), [ObservationTable](https://docs.featurebyte.com/latest/reference/core/observation_table/) and [HistoricalFeatureTable](https://docs.featurebyte.com/latest/reference/core/historical_feature_table/) objects, for more information.\n\n## Deploy when needed\n\nOnce a feature list is deployed, the FeatureByte Service automatically orchestrates the pre-computation of feature values and stores them in an online feature store for online and batch serving.\n\n``` python\n# Get feature list from the catalog\nfeature_list = catalog.get_feature_list(\n    "200 Features on Active Customers"\n)\n# Check Feature objects are PRODUCTION_READY.\n# A readiness metric of 100% should be returned.\nprint(feature_list.production_ready_fraction)\n# Create deployment\nmy_deployment = feature_list.deploy(\n    name="Deployment of 200 Features to predict customers purchases amount next 2 weeks",\n)\n# Activate deployment\nmy_deployment.enable()\n```\n\nUse the REST API service to retrieve feature values from the online feature store for online serving or use the SDK to retrieve batch of feature values from the online feature store for batch serving.\n\n### Online Serving\nFor online serving, the Deployment object provides REST API service templates that can be used to serve features. Python or shell script templates for the REST API service are retrieved from the Deployment object.\n\nGet online scoring code as a Python script:\n``` python\ndeployment = catalog.get_deployment(\n    "Deployment of 200 Features to predict customers purchases amount next 2 weeks"\n)\ndeployment.get_online_serving_code(language="python")\n```\n\nGet online scoring code as a Shell script:\n``` python\ndeployment.get_online_serving_code(language="sh")\n```\n\n### Batch Serving\nFor batch serving, the Deployment object is used to retrieve feature values for a batch request table containing entities values.\n\n``` python\nfrom datetime import datetime\nbatch_features = deployment.compute_batch_feature_table(\n    batch_request_table=batch_request_table,\n    batch_feature_table_name=\n        "Data to predict customers purchases next 2 w as of " +\n        datetime.utcnow().strftime(\'%Y-%m-%dT%H:%M:%SZ\')\n)\n# Download batch feature values as a Pandas DataFrame\nbatch_features_df = batch_features.to_pandas()\n```\n\nRefer to the SDK reference for the [Deployment](https://docs.featurebyte.com/latest/reference/core/deployment/), [BatchRequestTable](https://docs.featurebyte.com/latest/reference/core/batch_request_table/) and [BatchFeatureTable](https://docs.featurebyte.com/latest/reference/core/batch_feature_table/) objects, for more information.\n\n\n## Releases\n\nYou can see the list of available releases on the [Change Log](https://github.com/featurebyte/featurebyte/blob/main/CHANGELOG.md) page.\nReleases are versioned using the [Semantic Versions](https://semver.org/) specification.\n\n## License\n\n[![License](https://img.shields.io/github/license/featurebyte/featurebyte)](https://github.com/featurebyte/featurebyte/blob/main/LICENSE)\n\nThis project is licensed under the terms of the `Elastic License 2.0` license. See [LICENSE](https://github.com/featurebyte/featurebyte/blob/main/LICENSE) for more details.\n\n## Contributing\n[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg)](code_of_conduct.md)\n\nAll contributions are welcomed. Please adhere to the [Code of Conduct](https://github.com/featurebyte/featurebyte/blob/main/CODE_OF_CONDUCT.md) and read the\n[Developer\'s Guide](https://github.com/featurebyte/featurebyte/blob/main/CONTRIBUTING.md) to get started.\n',
    'author': 'FeatureByte',
    'author_email': 'it-admin@featurebyte.com',
    'maintainer': 'None',
    'maintainer_email': 'None',
    'url': 'https://featurebyte.com',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'extras_require': extras_require,
    'entry_points': entry_points,
    'python_requires': '>=3.8,<4.0',
}


setup(**setup_kwargs)
