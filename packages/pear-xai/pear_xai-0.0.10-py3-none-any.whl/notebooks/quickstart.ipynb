{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart\n",
    "In this notebook, we are going to showcase how to build a post-hoc explainer agreement neural network. We will break up\n",
    "this quickstart into the following sections:\n",
    "- Load Data\n",
    "- Create Model\n",
    "- Create Explainers\n",
    "- Create Disagreement Loss\n",
    "- Train Model\n",
    "- Save Model\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import SGD, Adam, AdamW\n",
    "\n",
    "import pear\n",
    "\n",
    "# Define constants\n",
    "dataset = \"californiahousing\"\n",
    "batch_size = 64\n",
    "model_cfg = {\"name\": \"mlp\",\n",
    "             \"width\": 100,\n",
    "             \"depth\": 3}\n",
    "optimizer = \"adamw\"\n",
    "lr = 5e-3\n",
    "weight_decay = 2e-4\n",
    "explainers = [\"vanilla_gradients\", \"integrated_gradients\"]\n",
    "disagreement_lambda = 0.25\n",
    "disagreement_mu = 0.5\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "californiahousing dataset with 15475 training samples and 5159 testing samples and 8 features and (tensor([0, 1]), tensor([7686, 7789])) classes.\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "loader_train, loader_test, num_classes = pear.get_data(dataset,\n",
    "                                                       batch_size,\n",
    "                                                       data_path=\"../pear/datasets\")\n",
    "input_dim = loader_train.dataset.data.shape[1]\n",
    "num_training_data = loader_train.dataset.data.shape[0]\n",
    "num_testing_data = loader_test.dataset.data.shape[0]\n",
    "print(f\"{dataset} dataset with {num_training_data} training samples and {num_testing_data} testing samples\"\n",
    "      f\" and {input_dim} features and \"\n",
    "      f\"{torch.unique(torch.tensor(loader_train.dataset.targets), return_counts=True)} classes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This mlp has 21.302 thousand parameters.\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model = pear.get_model(model_cfg, input_dim, num_classes)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"This {model_cfg['name']} has {pytorch_total_params / 1e3:0.3f} thousand parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Explainers (and optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an optimizer\n",
    "params = model.parameters()\n",
    "if optimizer == \"sgd\":\n",
    "    optim = SGD(params, lr=lr, weight_decay=weight_decay, momentum=0.9)\n",
    "elif optimizer == \"adam\":\n",
    "    optim = Adam(params, lr=lr, weight_decay=weight_decay)\n",
    "elif optimizer == \"adamw\":\n",
    "    optim = AdamW(params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# Create two explainers for the loss\n",
    "explainer_a = pear.get_explainer(explainers[0], model, torch.tensor(loader_train.dataset.data))\n",
    "explainer_b = pear.get_explainer(explainers[1], model, torch.tensor(loader_train.dataset.data))\n",
    "\n",
    "# Initialize LIME and SHAP for evaluation\n",
    "lime = pear.get_explainer(\"lime\", model, torch.tensor(loader_train.dataset.data))\n",
    "shap = pear.get_explainer(\"shap\", model, torch.tensor(loader_train.dataset.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Disagreement Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a metric and define a loss function\n",
    "disagreement_loss_fn = pear.DisagreementLoss(explainer_a, explainer_b, disagreement_mu)\n",
    "current_disagreement_lambda = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 | task loss 0.4101 | disagree loss 0.0043 | train bal acc 80.75 | test bal acc 80.04 | \n",
      "feature_agreement: 0.9988 | rank_agreement: 0.8640 | sign_agreement: 0.9988 | signed_rank_agreement: 0.8640 | rank_correlation: 0.9795 | pairwise_rank: 0.9714 | \n",
      "feature_agreement: 0.9988 | rank_agreement: 0.8568 | sign_agreement: 0.9988 | signed_rank_agreement: 0.8568 | rank_correlation: 0.9792 | pairwise_rank: 0.9709 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 | task loss 0.4054 | disagree loss 0.0043 | train bal acc 81.49 | test bal acc 82.28 | \n",
      "feature_agreement: 0.9844 | rank_agreement: 0.8476 | sign_agreement: 0.9844 | signed_rank_agreement: 0.8476 | rank_correlation: 0.9797 | pairwise_rank: 0.9734 | \n",
      "feature_agreement: 0.9848 | rank_agreement: 0.8216 | sign_agreement: 0.9848 | signed_rank_agreement: 0.8216 | rank_correlation: 0.9773 | pairwise_rank: 0.9706 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2 | task loss 0.3840 | disagree loss 0.0104 | train bal acc 82.67 | test bal acc 83.30 | \n",
      "feature_agreement: 0.9696 | rank_agreement: 0.6968 | sign_agreement: 0.9696 | signed_rank_agreement: 0.6968 | rank_correlation: 0.9547 | pairwise_rank: 0.9457 | \n",
      "feature_agreement: 0.9704 | rank_agreement: 0.6912 | sign_agreement: 0.9704 | signed_rank_agreement: 0.6912 | rank_correlation: 0.9544 | pairwise_rank: 0.9450 | \n"
     ]
    }
   ],
   "source": [
    "# TODO: set up tqdm\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    _ = model.train_loop(trainloader=loader_train,\n",
    "                         disagreement_lambda=current_disagreement_lambda,\n",
    "                         optimizer=optim,\n",
    "                         task_loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "                         disagreement_loss_fn=disagreement_loss_fn)\n",
    "    evaluation_on_train_data = model.evaluate_balanced(loader_train,\n",
    "                                                       task_loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "                                                       disagreement_loss_fn=disagreement_loss_fn)\n",
    "    evaluation_on_test_data = model.evaluate_balanced(loader_test,\n",
    "                                                      task_loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "                                                      disagreement_loss_fn=disagreement_loss_fn)\n",
    "\n",
    "    print(f\"epoch {epoch:2d} | \"\n",
    "          f\"task loss {evaluation_on_train_data['task_loss']:.4f} | \"\n",
    "          f\"disagree loss {evaluation_on_train_data['disagreement_loss']:.4f} | \"\n",
    "          f\"train bal acc {(evaluation_on_train_data['acc_0'] + evaluation_on_train_data['acc_1']) / 2:.2f} | \"\n",
    "          f\"test bal acc {(evaluation_on_test_data['acc_0'] + evaluation_on_test_data['acc_1']) / 2:.2f} | \"\n",
    "          )\n",
    "\n",
    "    disagreement_vals = pear.get_disagreement_values(loader_train, explainer_a, explainer_b, disagreement_k=5)\n",
    "    eval_str = f\"\"\n",
    "    for k in disagreement_vals.keys():\n",
    "        eval_str += f\"{k}: {disagreement_vals[k]:.4f} | \"\n",
    "    print(eval_str)\n",
    "\n",
    "    disagreement_vals = pear.get_disagreement_values(loader_test, explainer_a, explainer_b, disagreement_k=5)\n",
    "    eval_str = f\"\"\n",
    "    for k in disagreement_vals.keys():\n",
    "        eval_str += f\"{k}: {disagreement_vals[k]:.4f} | \"\n",
    "    print(eval_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results from this training run\n",
    "result = {\"model\": model_cfg[\"name\"],\n",
    "          \"dataset\": dataset,\n",
    "          \"task_loss_test_data\": evaluation_on_test_data['task_loss'],\n",
    "          \"disagreement_loss_test_data\": evaluation_on_test_data['disagreement_loss'],\n",
    "          \"task_loss_train_data\": evaluation_on_train_data['task_loss'],\n",
    "          \"disagreement_loss_train_data\": evaluation_on_train_data['disagreement_loss'],\n",
    "          \"train_acc\": evaluation_on_train_data['acc'],\n",
    "          \"test_acc\": evaluation_on_test_data['acc'],\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'mlp', 'dataset': 'californiahousing', 'task_loss_test_data': 0.373055636882782, 'disagreement_loss_test_data': 0.010415511259818282, 'task_loss_train_data': 0.3840358555316925, 'disagreement_loss_train_data': 0.010426596146510576, 'train_acc': 82.70759289176091, 'test_acc': 83.25256832719519}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}