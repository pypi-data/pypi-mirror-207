Metadata-Version: 2.1
Name: enot-autodl
Version: 3.3.1
Summary: AutoDL framework for neural network compression & acceleration
Home-page: https://enot.ai
Author: ENOT LLC
Author-email: enot@enot.ai
License: ENOT License v1.0
Keywords: AI,Neural architecture search
Classifier: License :: Other/Proprietary License
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: tblib
Requires-Dist: torch (<1.14.0,>=1.8.0)
Requires-Dist: torch-optimizer
Requires-Dist: torchvision
Requires-Dist: numpy (>=1.16.4)
Requires-Dist: pandas
Requires-Dist: scipy (>=1.2.2)
Requires-Dist: PyYAML
Requires-Dist: tqdm
Requires-Dist: tensorboard
Requires-Dist: requests
Requires-Dist: ipywidgets
Requires-Dist: pillow (>=6.2.1)
Requires-Dist: matplotlib (>=2.2.2)
Requires-Dist: fvcore
Requires-Dist: networkx
Requires-Dist: pulp (==2.4)
Requires-Dist: tabulate
Requires-Dist: onnx
Requires-Dist: ninja
Requires-Dist: botorch (<0.8.0,>=0.4.0)
Requires-Dist: optuna
Requires-Dist: onnx2torch
Requires-Dist: timm (<=0.6.13)
Requires-Dist: transformers (==4.19.2)

Embedded Network Optimization Technology

ENOT, or Embedded Network Optimization Technology, is a flexible tool for Deep Learning developers which automates
neural architecture optimization.
It can be useful in the following scenarios:
- Target metric maximization (e.g., classification accuracy or intersection over union);
- Target metric maximization with constrained computational resources (e.g., RAM, latency);

Framework advantages:
- Controlled ratio between latency and network performance;
- Networks in the pre-trained search space can exceed their stand-alone variants (in some scenarios);
- Compatibility with almost any DL task and simple integration with the existing training pipelines.
- Joint neural architecture search, prunning and distillation procedure can be applied to found optimal neural
network architecture.

To use this package please refer to our [documentation page](https://enot-autodl.rtd.enot.ai/en/stable/).

Visit [our website](https://enot.ai) for more information.
